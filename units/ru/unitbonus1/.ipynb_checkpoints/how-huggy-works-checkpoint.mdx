# Как работает Хагги [[how-huggy-works]]

Хагги - это среда глубокого обучения с подкреплением, созданная компанией Hugging Face и основанная на [проекте Puppo the Corgi команды Unity MLAgents](https://blog.unity.com/technology/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit).
Эта среда была создана с использованием [игрового движка Unity](https://unity.com/) и [MLAgents](https://github.com/Unity-Technologies/ml-agents). ML-Agents - это набор инструментов для игрового движка Unity, позволяющий **создавать окружающую среду с помощью Unity или использовать готовые среды для обучения наших агентов**.

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy.jpg" alt="Huggy" width="100%">

В этой среде мы стремимся научить Хагги **ловить палку, которую мы бросаем. Это означает, что он должен правильно двигаться к палке**.

## Пространство состояний, то, что воспринимает Хагги.  [[state-space]]
Хагги не "видит" окружающую среду. Вместо этого мы предоставляем ему информацию об окружающей среде:

- Положение цели (палки)
- Относительное положение между собой и целью
- Ориентация ног.

Учитывая всю эту информацию, Хагги может **использовать свою политику, чтобы определить, какие действия следует предпринять дальше для достижения своей цели**.

## Пространство действий, какие движения может выполнять Хагги [[action-space]]
<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy-action.jpg" alt="Huggy action" width="100%">

**Суставные двигатели приводят в движение ноги Хагги**. Это означает, что для достижения цели Хагги должен **научиться правильно вращать суставные двигатели каждой из своих ног, чтобы они могли двигаться**.

## Функция вознаграждения [[reward-function]]

Функция вознаграждения разработана таким образом, чтобы **Хагги выполнил свою задачу**: принес палку.

Помните, что одной из основ обучения с подкреплением является *гипотеза вознаграждения*: цель может быть описана как **максимизация ожидаемого кумулятивного вознаграждения**.

Здесь наша цель состоит в том, чтобы Хагги **пошел к палке, но без сильного вращения**. Следовательно, наша функция вознаграждения должна транслировать эту цель.

Наша функция вознаграждения:

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/reward.jpg" alt="Huggy reward function" width="100%">

- *Бонус ориентации*: мы **награждаем его за приближение к цели**.
- *Штраф времени*: фиксированный штраф времени, который дается при каждом действии, чтобы **заставить его добраться до палки как можно быстрее**.
- *Штраф за вращение*: мы штрафуем Хагги, если **он слишком сильно вращается и слишком быстро поворачивается**.
- *Вознаграждение за достижение цели*: мы награждаем Хагги за **достижение цели**.

Если вы хотите посмотреть, как эта функция вознаграждения выглядит математически, посмотрите [презентацию Puppo the Corgi](https://blog.unity.com/technology/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit).

## Обучение Хагги

Задача Хагги - **научиться правильно и как можно быстрее бежать к цели**. Для этого на каждом шагу и с учетом наблюдения за окружающей средой ему нужно решать, как вращать каждый суставной двигатель своих ног, чтобы правильно (не слишком сильно вращаясь) двигаться к цели.

Цикл обучения выглядит следующим образом:

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy-loop.jpg" alt="Huggy loop" width="100%">


Учебная среда выглядит следующим образом:

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/training-env.jpg" alt="Huggy training env" width="100%">


Это место, где случайным образом появляется **палка**. Когда Хагги достигает ее, палка появляется в другом месте.
Для обучения мы создали **множество копий окружения**. Это помогает ускорить обучение за счет более разнообразного опыта.



Теперь, когда у вас есть общая картина среды, вы готовы обучить Хагги приносить палку.

Для этого мы будем использовать [MLAgents](https://github.com/Unity-Technologies/ml-agents). Не волнуйтесь, если вы никогда не использовали его раньше. В этом блоке мы будем использовать Google Colab для обучения Хагги, а затем вы сможете загрузить своего обученного Хагги и играть с ним прямо в браузере.

В одном из следующих блоков мы более подробно изучим MLAgents и посмотрим, как это работает. Пока же мы ограничимся простой реализацией.
